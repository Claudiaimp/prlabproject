#we have imported the three main libraries needed 
import json
import pandas as pd
import requests

#We have created a variable assigning the integer 12 
#and we have also created an empty list called 'datafr'
num_of_pages = 12
datafr = []

#we opened a “for” cycle that iterates the page numbers within the url
#Then we use the command “request.get” so that all form data is encoded into the url
for n in range(1, num_of_pages):
    url = "https://api.artic.edu/api/v1/artworks?page=" + str(n) + "&limit=100"
    response = requests.get(url)
    json_data = response.json()
    
#Then we have appended to our list the 'data' values from the API
    for d in json_data['data']:
        datafr.append(d)

#We created a csv file with all our observations
#We have also replaced the not available data with 0 
#The final data set with more than one thousand observations is done 
csv_file_path = "art1000.csv"
df = pd.DataFrame(datafr)
df.fillna(0,inplace = True)
df.to_csv(csv_file_path, header=True, index=False)
